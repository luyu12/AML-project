{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "import scipy\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DataLoader(object):\n",
    "    \n",
    "    def __init__(self, dataset_name):\n",
    "        self.loadLIBSVMData(dataset_name)\n",
    "        if dataset_name == \"scene\":\n",
    "            self.num_class = 6\n",
    "        elif dataset_name == \"yeast\":\n",
    "            self.num_class = 14\n",
    "        elif dataset_name == \"siam\":\n",
    "            self.num_class = 22\n",
    "        elif dataset_name == \"topics\":\n",
    "            self.num_class = 101\n",
    "        \n",
    "        self.train_data_size = self.train_data.shape[0]\n",
    "        self.test_data_size = self.test_data.shape[0]\n",
    "        self.num_feature = self.train_data.shape[1]\n",
    "        \n",
    "        self.shuffle()\n",
    "    \n",
    "    def loadLIBSVMData(self, name):\n",
    "        train_data, train_labels = load_svmlight_file('./datasets/{name}/{name}_train.svm'.format(name=name), multilabel=True)\n",
    "        self.train_data = train_data.toarray()\n",
    "        self.train_labels = train_labels\n",
    "        test_data, test_labels = load_svmlight_file('./datasets/{name}/{name}_test.svm'.format(name=name), multilabel=True)\n",
    "        self.test_data = test_data.toarray()\n",
    "        self.test_labels = test_labels\n",
    "    \n",
    "    def shuffle(self):\n",
    "        shuffle = np.random.permutation(self.train_data_size)\n",
    "        self.train_data = self.train_data[shuffle]\n",
    "        labels = []\n",
    "        for i in shuffle:\n",
    "            labels.append(self.train_labels[i])\n",
    "        self.train_labels = labels\n",
    "        \n",
    "        shuffle = np.random.permutation(self.test_data_size)\n",
    "        self.test_data = self.test_data[shuffle]\n",
    "        labels = []\n",
    "        for i in shuffle:\n",
    "            labels.append(self.test_labels[i])\n",
    "        self.test_labels = labels\n",
    "        \n",
    "    def trainGenerator(self, method):\n",
    "        if method == 'PT1':\n",
    "            for i in range(self.train_data_size):\n",
    "                rand = random.randint(0, len(self.train_labels[i]) - 1)\n",
    "                yield (self.train_data[i].reshape(1, -1), self.train_labels[i][rand])\n",
    "        elif method == 'PT3':\n",
    "            for i in range(self.train_data_size):\n",
    "                res = 0\n",
    "                for label in self.train_labels[i]:\n",
    "                    res += 1 << int(label)\n",
    "                yield (self.train_data[i].reshape(1, -1), res)\n",
    "        elif method == 'PT5':\n",
    "            for i in range(self.train_data_size):\n",
    "                for label in self.train_labels[i]:\n",
    "                    yield (self.train_data[i].reshape(1, -1), res)\n",
    "    \n",
    "    def testGenerator(self, method):\n",
    "        if method == 'PT3':\n",
    "            for i in range(self.test_data_size):\n",
    "                res = 0\n",
    "                for label in self.train_labels[i]:\n",
    "                    res += 1 << int(label)\n",
    "                yield (self.test_data[i].reshape(1, -1), res)\n",
    "        else:\n",
    "            for i in range(self.test_data_size):\n",
    "                yield (self.test_data[i].reshape(1, -1), self.test_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class OnlineClassification(object):\n",
    "    \n",
    "    def __init__(self, num_feature, learning_rate='constant', eta0=0.01):\n",
    "        self.classifier = SGDClassifier(learning_rate=learning_rate, eta0=eta0, warm_start=True)\n",
    "        \n",
    "    def train(self, x, c):\n",
    "        self.classifier.partial_fit(x, np.array([c]), [-1, 1])\n",
    "        \n",
    "    def test(self, x):\n",
    "        return self.classifier.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Node(object):\n",
    "    \n",
    "    def __init__(self, num_feature, learning_rate='constant', eta0=0.01):\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.parent = None\n",
    "        self.max_label = 1\n",
    "        self.max_label_count = 0\n",
    "        self.n_all = 0\n",
    "        self.m_all = 0\n",
    "        self.C = 0\n",
    "        self.l = {}\n",
    "        self.n = {}\n",
    "        self.m = {}\n",
    "        self.model = OnlineClassification(num_feature, learning_rate=learning_rate, eta0=eta0)\n",
    "    \n",
    "    def reset(self):\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.parent = None\n",
    "        self.max_label = 1\n",
    "        self.max_label_count = 0\n",
    "        self.n_all = 0\n",
    "        self.m_all = 0\n",
    "        self.C = 0\n",
    "        self.l.clear()\n",
    "        self.n.clear()\n",
    "        self.m.clear()\n",
    "\n",
    "    def testModel(self, x):\n",
    "        return self.model.test(x)\n",
    "    \n",
    "    def trainModel(self, x, c):\n",
    "        self.model.train(x, c)\n",
    "        \n",
    "    def addClass(self, class_name):\n",
    "        self.n[class_name] = 0\n",
    "        self.m[class_name] = 0\n",
    "        self.l[class_name] = 0\n",
    "        \n",
    "    def findExpectationAll(self):\n",
    "        if self.n_all == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return self.m_all / self.n_all\n",
    "        \n",
    "    def findExpectationOneClass(self, y):\n",
    "        if self.n[y] == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return self.m[y] / self.n[y]\n",
    "    \n",
    "    def judgeInTrain(self, y):\n",
    "        #c == -1: left, c == 1: right\n",
    "        return -1 if self.findExpectationAll() > self.findExpectationOneClass(y) else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Tree(object):\n",
    "    def __init__(self, T, data_loader, method='PT1', threshold=0.5, Rs=16, epoch=1, learning_rate='constant', eta0=0.01):\n",
    "        self.data_loader = data_loader\n",
    "        self.num_feature = data_loader.num_feature\n",
    "        self.method = method\n",
    "        self.threshold = threshold\n",
    "        self.eta0 = eta0;\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epoch = epoch\n",
    "        self.Rs = Rs\n",
    "        self.T = T\n",
    "        self.t = 1\n",
    "        self.size = 0\n",
    "        self.root = self.generateNode()\n",
    "        \n",
    "    def generateNode(self):\n",
    "        node = Node(self.num_feature, self.learning_rate, self.eta0)\n",
    "        self.size = self.size + 1\n",
    "        return node\n",
    "        \n",
    "    def split(self, node):\n",
    "        self.t = self.t + 1\n",
    "        left = self.generateNode()\n",
    "        right = self.generateNode()\n",
    "        \n",
    "        node.left = left\n",
    "        left.parent = node\n",
    "        node.right = right\n",
    "        right.parent = node\n",
    "        \n",
    "    def swap(self, node):\n",
    "        cur = self.root\n",
    "        while cur.left != None:\n",
    "            cur = cur.left if cur.left.C < cur.right.C else cur.right\n",
    "        \n",
    "        parent = cur.parent\n",
    "        grandpa = parent.parent\n",
    "        sib = parent.left if parent.left == cur else parent.right\n",
    "        if parent == grandpa.left:\n",
    "            grandpa.left = sib\n",
    "        else:\n",
    "            grandpa.right = sib\n",
    "        sib.parent = grandpa\n",
    "        \n",
    "        self.updateC(sib)\n",
    "        cur.reset()\n",
    "        parent.reset()\n",
    "        node.left = cur\n",
    "        cur.parent = node\n",
    "        node.right = parent\n",
    "        parent.parent = node\n",
    "        \n",
    "    def updateC(self, node):\n",
    "        while node != self.root and node.parent.C != node.C:\n",
    "            node = node.parent\n",
    "            node.C = min(node.left.C, node.right.C)\n",
    "    \n",
    "    def train(self):\n",
    "        start = time.time()\n",
    "        print('Start training.......')\n",
    "        for i in range(self.epoch):\n",
    "            train_generator = self.data_loader.trainGenerator(self.method)\n",
    "            for sample in train_generator:\n",
    "                self.fitOne(sample)\n",
    "            acc, pre, rec = self.test()\n",
    "            print('epoch %d: >>>>>>>> acc=%.3f, pre=%.3f, rec=%.3f' % (i, acc, pre, rec))\n",
    "            print('left: %d, right: %d' % (self.root.left.n_all, self.root.right.n_all))\n",
    "        end = time.time()\n",
    "        print('time used: %d s' % (end - start))\n",
    "    \n",
    "    def test(self):\n",
    "        test_generator = self.data_loader.testGenerator(self.method)\n",
    "        acc_list = []\n",
    "        pre_list = []\n",
    "        rec_list = []\n",
    "        for sample in test_generator:\n",
    "            x, y = sample\n",
    "            y_hat = self.predict(x)\n",
    "            acc, pre, rec = self.score(y, y_hat)\n",
    "            acc_list.append(acc)\n",
    "            pre_list.append(pre)\n",
    "            rec_list.append(rec)\n",
    "        \n",
    "        return np.mean(acc_list), np.mean(pre_list), np.mean(rec_list)\n",
    "    \n",
    "    def score(self, y, y_hat):\n",
    "        # used for debug\n",
    "#         print (y, y_hat)\n",
    "        if self.method == 'PT3':\n",
    "            res = 0\n",
    "            for i in y_hat:\n",
    "                res = res | i\n",
    "            intersect = bin(y & res).count('1')\n",
    "            union = bin(y | res).count('1')\n",
    "#             print(y, y_hat, intersect, union)\n",
    "            return intersect / union, intersect / bin(res).count('1'), intersect / bin(y).count('1')\n",
    "        else:\n",
    "            y = set(y)\n",
    "            y_hat = set(y_hat)\n",
    "            intersect = len(y.intersection(y_hat))\n",
    "            union = len(y.union(y_hat))\n",
    "            return intersect / union, intersect / len(y_hat), intersect / len(y)\n",
    "    \n",
    "    def fitOne(self, xy):\n",
    "        x, y = xy\n",
    "        node = self.root\n",
    "        #register if y is new in this node\n",
    "        while node != None:\n",
    "            not_registered = node.l.get(y) == None\n",
    "            if not_registered:\n",
    "                node.addClass(y)\n",
    "            \n",
    "            node.l[y] += 1\n",
    "            \n",
    "            if node.l[y] > node.max_label_count:\n",
    "                node.max_label = y\n",
    "                node.max_label_count = node.l[y]\n",
    "\n",
    "            #give birth or swap in a leaf node if num_class >= 2 or \n",
    "            if node.left == None and len(node.n) > 1:\n",
    "                if self.t < self.T or node.C - node.l[node.max_label] > self.Rs * (self.root.C + 1):\n",
    "                    if self.t < self.T:\n",
    "                        #give birth\n",
    "                        self.split(node)\n",
    "                    else:\n",
    "                        #swap\n",
    "                        self.swap(node)\n",
    "                    node.left.C = node.C // 2\n",
    "                    node.right.C = node.C - node.left.C\n",
    "                    node.left.max_label = node.max_label\n",
    "                    node.right.max_label = node.max_label\n",
    "                    self.updateC(node.left)\n",
    "\n",
    "            #train if node is not leaf\n",
    "            if node.left != None:\n",
    "                c = node.judgeInTrain(y)\n",
    "                node.trainModel(x, c)\n",
    "                c_hat = node.testModel(x)\n",
    "                node.n_all += 1\n",
    "                node.m_all += c_hat\n",
    "                node.n[y] += 1\n",
    "                node.m[y] += c_hat\n",
    "                \n",
    "                node = node.left if c_hat == -1 else node.right\n",
    "            else:\n",
    "                node.C += 1\n",
    "                self.updateC(node)\n",
    "                break\n",
    "\n",
    "    def predict(self, x):\n",
    "        node = self.root\n",
    "        while node.left != None:\n",
    "            node = node.left if node.testModel(x) == -1 else node.right\n",
    "        max_frq = node.max_label_count\n",
    "        res = []\n",
    "        for label, frq in node.l.items():\n",
    "            if frq > self.threshold * max_frq:\n",
    "                res.append(label)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data size: 1211, test data size: 1196, num of features: 294, num of classes: 6\n"
     ]
    }
   ],
   "source": [
    "#build\n",
    "dataset_name = 'scene'\n",
    "data_loader = DataLoader(dataset_name)\n",
    "K = data_loader.num_class\n",
    "print('training data size: %d, test data size: %d, num of features: %d, num of classes: %d' % (data_loader.train_data_size, data_loader.test_data_size, data_loader.num_feature, data_loader.num_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_name='siam', T=87, Rs=256, learning_rate='optimal', eta0=0.10, epoch=5\n",
      "Start training.......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Whisper\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-c0416f4d226c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'dataset_name=\\'%s\\', T=%d, Rs=%d, learning_rate=\\'%s\\', eta0=%.2f, epoch=%d'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0meta0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m#train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mLOM_tree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-5-81f55fccdf14>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[0mtrain_generator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainGenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfitOne\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m             \u001b[0macc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpre\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'epoch %d: >>>>>>>> acc=%.3f, pre=%.3f, rec=%.3f'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpre\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-81f55fccdf14>\u001b[0m in \u001b[0;36mfitOne\u001b[1;34m(self, xy)\u001b[0m\n\u001b[0;32m    135\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m                 \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjudgeInTrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m                 \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m                 \u001b[0mc_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtestModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m                 \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_all\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-95907287c406>\u001b[0m in \u001b[0;36mtrainModel\u001b[1;34m(self, x, c)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtrainModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0maddClass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-1bfd9c044da3>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, x, c)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Whisper\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[1;34m(self, X, y, classes, sample_weight)\u001b[0m\n\u001b[0;32m    551\u001b[0m                                  \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m                                  \u001b[0mclasses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 553\u001b[1;33m                                  coef_init=None, intercept_init=None)\n\u001b[0m\u001b[0;32m    554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m     def fit(self, X, y, coef_init=None, intercept_init=None,\n",
      "\u001b[1;32mC:\\Users\\Whisper\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py\u001b[0m in \u001b[0;36m_partial_fit\u001b[1;34m(self, X, y, alpha, C, loss, learning_rate, max_iter, classes, sample_weight, coef_init, intercept_init)\u001b[0m\n\u001b[0;32m    403\u001b[0m                              \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m                              \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 405\u001b[1;33m                              max_iter=max_iter)\n\u001b[0m\u001b[0;32m    406\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m             raise ValueError(\"The number of class labels must be \"\n",
      "\u001b[1;32mC:\\Users\\Whisper\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py\u001b[0m in \u001b[0;36m_fit_binary\u001b[1;34m(self, X, y, alpha, C, sample_weight, learning_rate, max_iter)\u001b[0m\n\u001b[0;32m    459\u001b[0m                                               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_expanded_class_weight\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m                                               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_expanded_class_weight\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 461\u001b[1;33m                                               sample_weight)\n\u001b[0m\u001b[0;32m    462\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    463\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt_\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mn_iter_\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Whisper\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py\u001b[0m in \u001b[0;36mfit_binary\u001b[1;34m(est, i, X, y, alpha, C, learning_rate, max_iter, pos_weight, neg_weight, sample_weight)\u001b[0m\n\u001b[0;32m    297\u001b[0m                          \u001b[0mpos_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneg_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m                          \u001b[0mlearning_rate_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meta0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 299\u001b[1;33m                          est.power_t, est.t_, intercept_decay)\n\u001b[0m\u001b[0;32m    300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "T = 4*K - 1\n",
    "Rs = 256\n",
    "learning_rate = 'optimal'\n",
    "eta0 = 0.1\n",
    "epoch = 5\n",
    "method = 'PT3'\n",
    "threshold = 0.5\n",
    "\n",
    "LOM_tree = Tree(T, data_loader, method=method, threshold=threshold, epoch=epoch, Rs=Rs, learning_rate=learning_rate, eta0=eta0)\n",
    "\n",
    "print('dataset_name=\\'%s\\', T=%d, Rs=%d, learning_rate=\\'%s\\', eta0=%.2f, epoch=%d' % (dataset_name, T, Rs, learning_rate,  eta0, epoch))\n",
    "#train\n",
    "LOM_tree.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check balance\n",
    "count = 0\n",
    "node = LOM_tree.root\n",
    "print(node.left.n_all, node.right.n_all)\n",
    "while node != None:\n",
    "    node = node.left\n",
    "    count += 1\n",
    "print(count)\n",
    "\n",
    "count = 0\n",
    "node = LOM_tree.root\n",
    "while node != None:\n",
    "    node = node.right\n",
    "    count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 11100010101\n",
    "bin(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
