{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DataLoader(object):\n",
    "    \n",
    "    def __init__(self, dataset_name):\n",
    "        if dataset_name == \"mnist\":\n",
    "            self.loadMnistData()\n",
    "            self.num_class = 10\n",
    "        elif dataset_name == \"isolet\":\n",
    "            self.loadIsoletData()\n",
    "            self.num_class = 26\n",
    "        elif dataset_name == \"sector\":\n",
    "            self.loadSectorData()\n",
    "            self.num_class = 105\n",
    "        elif dataset_name == \"aloi\":\n",
    "            self.loadAloiData()\n",
    "            self.num_class = 1000\n",
    "        else:\n",
    "            raise ValueError('No such dataset name exists.')\n",
    "        \n",
    "        self.train_data_size = self.train_data.shape[0]\n",
    "        self.test_data_size = self.test_data.shape[0]\n",
    "        self.num_feature = self.train_data.shape[1]\n",
    "        \n",
    "        self.shuffle()\n",
    "    \n",
    "    def loadMnistData(self):\n",
    "        train_data, train_labels = load_svmlight_file('./datasets/mnist/mnist.scale')\n",
    "        self.train_data = train_data.toarray()\n",
    "        self.train_labels = train_labels\n",
    "        test_data, test_labels = load_svmlight_file('./datasets/mnist/mnist.scale.t')\n",
    "        self.test_data = test_data.toarray()\n",
    "        self.test_labels = test_labels\n",
    "            \n",
    "    def loadIsoletData(self):\n",
    "        train_set = np.genfromtxt('./datasets/isolet/isolet_data.data',\n",
    "                         dtype=None,\n",
    "                         delimiter=',')\n",
    "        test_set = np.genfromtxt('./datasets/isolet/isolet5.data',\n",
    "                         dtype=None,\n",
    "                         delimiter=',')\n",
    "        \n",
    "        self.train_data = train_set[:,:-1]\n",
    "        self.train_labels = train_set[:,-1].astype(int)\n",
    "        self.test_data = test_set[:,:-1]\n",
    "        self.test_labels = test_set[:,-1].astype(int) \n",
    "    \n",
    "    def loadSectorData(self):\n",
    "        data, labels = load_svmlight_file('./datasets/sector/sector.scale')\n",
    "        self.data = data.toarray()\n",
    "        n_tr = int(len(data) * 0.9)\n",
    "        \n",
    "        self.train_data = data[:n_tr]\n",
    "        self.train_labels = labels[:n_tr]\n",
    "        \n",
    "        self.test_data = data[n_tr:]\n",
    "        self.test_labels = labels[n_tr:]\n",
    "        \n",
    "    def loadAloiData(self):\n",
    "        data, labels = load_svmlight_file('./datasets/aloi/aloi.scale')\n",
    "        data = data.toarray()\n",
    "        n_tr = int(len(data) * 0.9)\n",
    "        \n",
    "        self.train_data = data[:n_tr]\n",
    "        self.train_labels = labels[:n_tr]\n",
    "        \n",
    "        self.test_data = data[n_tr:]\n",
    "        self.test_labels = labels[n_tr:]\n",
    "    \n",
    "    def shuffle(self):\n",
    "        shuffle = np.random.permutation(self.train_data_size)\n",
    "        self.train_data = self.train_data[shuffle]\n",
    "        self.train_labels = self.train_labels[shuffle]\n",
    "        \n",
    "        shuffle = np.random.permutation(self.test_data_size)\n",
    "        self.test_data = self.test_data[shuffle]\n",
    "        self.test_labels = self.test_labels[shuffle]\n",
    "        \n",
    "    def generator(self, train=True):\n",
    "        if train:\n",
    "            for i in range(self.train_data_size):\n",
    "                yield (self.train_data[i].reshape(1, -1), self.train_labels[i])\n",
    "        else:\n",
    "            for i in range(self.test_data_size):\n",
    "                yield (self.test_data[i].reshape(1, -1), self.test_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class OnlineLogistRegression(object):\n",
    "    \n",
    "    def __init__(self, num_feature, eta0=0.01):\n",
    "        self.w = .01 * (np.random.rand(num_feature + 1) - 0.5)\n",
    "        self.lr = eta0\n",
    "    \n",
    "    def reset(self):\n",
    "        self.w = .01 * (np.random.rand(len(self.w)) - 0.5)\n",
    "        \n",
    "    def train(self, x, c):\n",
    "        A = np.concatenate((np.array([1]), x), axis=0)\n",
    "        y_hat = A.dot(self.w)\n",
    "        c_hat = 1 / (1 + np.exp(-y_hat))\n",
    "        \n",
    "        fgrad = A.T.dot(c_hat - c)\n",
    "        self.w = self.w - self.lr * fgrad\n",
    "        \n",
    "    def test(self, x):\n",
    "        A = np.concatenate((np.array([1]), x),axis=0)\n",
    "        y_hat = A.dot(self.w)\n",
    "        \n",
    "        return 1 / (1 + np.exp(-y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class OnlineClassification(object):\n",
    "    \n",
    "    def __init__(self, num_feature, learning_rate='constant', eta0=0.01):\n",
    "        self.classifier = SGDClassifier(learning_rate=learning_rate, eta0=eta0, warm_start=True)\n",
    "        \n",
    "    def train(self, x, c):\n",
    "        self.classifier.partial_fit(x, np.array([c]), [0, 1])\n",
    "        \n",
    "    def test(self, x):\n",
    "        return self.classifier.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Node(object):\n",
    "    \n",
    "    def __init__(self, num_feature, learning_rate='constant', eta0=0.01):\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.parent = None\n",
    "        self.max_label = 1\n",
    "        self.max_label_count = 0\n",
    "        self.n_all = 0\n",
    "        self.m_all = 0\n",
    "        self.C = 0\n",
    "        self.l = {}\n",
    "        self.n = {}\n",
    "        self.m = {}\n",
    "        self.model = OnlineClassification(num_feature, learning_rate=learning_rate, eta0=eta0)\n",
    "#         self.model = OnlineLogistRegression(num_feature, lr)\n",
    "    \n",
    "    def reset(self):\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.parent = None\n",
    "        self.max_label = 1\n",
    "        self.max_label_count = 0\n",
    "        self.n_all = 0\n",
    "        self.m_all = 0\n",
    "        self.C = 0\n",
    "        self.l.clear()\n",
    "        self.n.clear()\n",
    "        self.m.clear()\n",
    "\n",
    "    def testModel(self, x):\n",
    "        return self.model.test(x)\n",
    "    \n",
    "    def trainModel(self, x, c):\n",
    "        self.model.train(x, c)\n",
    "        \n",
    "    def addClass(self, class_name):\n",
    "        self.n[class_name] = 0\n",
    "        self.m[class_name] = 0\n",
    "        self.l[class_name] = 0\n",
    "        \n",
    "    def findExpectationAll(self):\n",
    "        if self.n_all == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return self.m_all / self.n_all\n",
    "        \n",
    "    def findExpectationOneClass(self, y):\n",
    "        if self.n[y] == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return self.m[y] / self.n[y]\n",
    "    \n",
    "    def judgeInTrain(self, y):\n",
    "        #c == 0: left, c == 1: right\n",
    "        return int(self.findExpectationAll() <= self.findExpectationOneClass(y))\n",
    "    \n",
    "    def judgeInTest(self, x):\n",
    "        return int(self.findExpectationAll() <= self.testModel(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Tree(object):\n",
    "    def __init__(self, T, data_loader, Rs=16, learning_rate='constant', eta0=0.01):\n",
    "        self.data_loader = data_loader\n",
    "        self.num_feature = data_loader.num_feature\n",
    "        self.eta0 = eta0;\n",
    "        self.learning_rate = learning_rate\n",
    "        self.Rs = Rs\n",
    "        self.T = T\n",
    "        self.t = 1\n",
    "        self.size = 0\n",
    "        self.root = self.generateNode()\n",
    "        \n",
    "    def generateNode(self):\n",
    "        node = Node(self.num_feature, self.learning_rate, self.eta0)\n",
    "        self.size = self.size + 1\n",
    "        return node\n",
    "        \n",
    "    def split(self, node):\n",
    "        self.t = self.t + 1\n",
    "        left = self.generateNode()\n",
    "        right = self.generateNode()\n",
    "        \n",
    "        node.left = left\n",
    "        left.parent = node\n",
    "        node.right = right\n",
    "        right.parent = node\n",
    "        \n",
    "    def swap(self, node):\n",
    "        cur = self.root\n",
    "        while cur.left != None:\n",
    "            if cur.left.C < cur.right.C:\n",
    "                cur = cur.left\n",
    "            else:\n",
    "                cur = cur.right\n",
    "        parent = cur.parent\n",
    "        grandpa = parent.parent\n",
    "        sib = [parent.left, parent.right][int(parent.left == cur)]\n",
    "        if parent == grandpa.left:\n",
    "            grandpa.left = sib\n",
    "        else:\n",
    "            grandpa.right = sib\n",
    "        sib.parent = grandpa\n",
    "        \n",
    "        self.updateC(sib)\n",
    "        cur.reset()\n",
    "        parent.reset()\n",
    "        node.left = cur\n",
    "        cur.parent = node\n",
    "        node.right = parent\n",
    "        parent.parent = node\n",
    "        \n",
    "    def updateC(self, node):\n",
    "        while node != self.root and node.parent.C != node.C:\n",
    "            node = node.parent\n",
    "            node.C = min(node.left.C, node.right.C)\n",
    "        \n",
    "    def onlineTrain(self, xy):\n",
    "        x, y = xy\n",
    "        node = self.root\n",
    "        #register if y is new in this node\n",
    "        while node != None:\n",
    "            not_registered = node.l.get(y) == None\n",
    "            if not_registered:\n",
    "                node.addClass(y)\n",
    "            \n",
    "            node.l[y] += 1\n",
    "            \n",
    "            if node.l[y] > node.max_label_count:\n",
    "                node.max_label = y\n",
    "                node.max_label_count = node.l[y]\n",
    "\n",
    "            #give birth or swap in a leaf node if num_class >= 2 or \n",
    "            if node.left == None and len(node.n) > 1:\n",
    "                if self.t < self.T or node.C - node.l[node.max_label] > self.Rs * (self.root.C + 1):\n",
    "                    if self.t < self.T:\n",
    "                        #give birth\n",
    "                        self.split(node)\n",
    "                    else:\n",
    "                        #swap\n",
    "                        self.swap(node)\n",
    "                    node.left.C = node.C / 2\n",
    "                    node.right.C = node.C - node.left.C\n",
    "                    node.left.max_label = node.max_label\n",
    "                    node.right.max_label = node.max_label\n",
    "                    self.updateC(node.left)\n",
    "\n",
    "            #train if node is not leaf\n",
    "            if node.left != None:\n",
    "                c = node.judgeInTrain(y)\n",
    "                node.trainModel(x, c)\n",
    "                c_hat = int(node.testModel(x))\n",
    "                node.n_all += 1\n",
    "                node.m_all += c_hat\n",
    "                node.n[y] += 1\n",
    "                node.m[y] += c_hat\n",
    "                \n",
    "                node = [node.left, node.right][c_hat]\n",
    "            else:\n",
    "                node.C += 1\n",
    "                self.updateC(node)\n",
    "                break\n",
    "\n",
    "    def onlineTest(self, x):\n",
    "        node = self.root\n",
    "        while node.left != None:\n",
    "            node = [node.left, node.right][node.judgeInTest(x)]\n",
    "        return node.max_label\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6238 1559\n"
     ]
    }
   ],
   "source": [
    "#build\n",
    "dataset_name = \"isolet\"\n",
    "data_loader = DataLoader(dataset_name)\n",
    "K = data_loader.num_class\n",
    "print(data_loader.train_data_size, data_loader.test_data_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_name='isolet', T=51, Rs=128, learning_rate='optimal', eta0=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Whisper\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accurancy = 0.811\n"
     ]
    }
   ],
   "source": [
    "T = 2*K - 1\n",
    "Rs = 128\n",
    "eta0 = 0.1\n",
    "learning_rate = 'optimal'\n",
    "\n",
    "LOM_tree = Tree(T, data_loader, Rs=Rs, learning_rate=learning_rate, eta0=eta0)\n",
    "train_generator = data_loader.generator(train=True)\n",
    "test_generator = data_loader.generator(train=False)\n",
    "\n",
    "print('dataset_name=\\'%s\\', T=%d, Rs=%d, learning_rate=\\'%s\\', eta0=%d' % (dataset_name, T, Rs, learning_rate,  eta0))\n",
    "#train\n",
    "for i in range(5000):\n",
    "    LOM_tree.onlineTrain(next(train_generator))\n",
    "\n",
    "\n",
    "#test\n",
    "test_result = []\n",
    "for i in range(1000):\n",
    "    x, y = next(test_generator)\n",
    "    test_result.append(int(y == LOM_tree.onlineTest(x)))\n",
    "accurancy = np.mean(test_result)\n",
    "print('accurancy =', accurancy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
