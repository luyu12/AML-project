{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DataLoader(object):\n",
    "    \n",
    "    def __init__(self, dataset_name):\n",
    "        if dataset_name == \"mnist\":\n",
    "            self.loadMnistData()\n",
    "            self.num_class = 10\n",
    "        elif dataset_name == \"isolet\":\n",
    "            self.loadIsoletData()\n",
    "            self.num_class = 26\n",
    "        elif dataset_name == \"sector\":\n",
    "            self.loadSectorData()\n",
    "            self.num_class = 105\n",
    "        elif dataset_name == \"aloi\":\n",
    "            self.loadAloiData()\n",
    "            self.num_class = 1000\n",
    "        else:\n",
    "            raise ValueError('No such dataset name exists.')\n",
    "        \n",
    "        self.train_data_size = self.train_data.shape[0]\n",
    "        self.test_data_size = self.test_data.shape[0]\n",
    "        self.num_feature = self.train_data.shape[1]\n",
    "        \n",
    "        self.shuffle()\n",
    "    \n",
    "    def loadMnistData(self):\n",
    "        train_data, train_labels = load_svmlight_file('./datasets/mnist/mnist.scale')\n",
    "        self.train_data = train_data.toarray()\n",
    "        self.train_labels = train_labels\n",
    "        test_data, test_labels = load_svmlight_file('./datasets/mnist/mnist.scale.t')\n",
    "        self.test_data = test_data.toarray()\n",
    "        self.test_labels = test_labels\n",
    "            \n",
    "    def loadIsoletData(self):\n",
    "        train_set = np.genfromtxt('./datasets/isolet/isolet_data.data',\n",
    "                         dtype=None,\n",
    "                         delimiter=',')\n",
    "        test_set = np.genfromtxt('./datasets/isolet/isolet5.data',\n",
    "                         dtype=None,\n",
    "                         delimiter=',')\n",
    "        \n",
    "        self.train_data = train_set[:,:-1]\n",
    "        self.train_labels = train_set[:,-1].astype(int)\n",
    "        self.test_data = test_set[:,:-1]\n",
    "        self.test_labels = test_set[:,-1].astype(int) \n",
    "    \n",
    "    def loadSectorData(self):\n",
    "        data, labels = load_svmlight_file('./datasets/sector/sector.scale')\n",
    "        data = data.toarray()\n",
    "        n_tr = int(data.shape[0] * 0.9)\n",
    "        \n",
    "        self.train_data = data[:n_tr]\n",
    "        self.train_labels = labels[:n_tr]\n",
    "        \n",
    "        self.test_data = data[n_tr:]\n",
    "        self.test_labels = labels[n_tr:]\n",
    "        \n",
    "    def loadAloiData(self):\n",
    "        data, labels = load_svmlight_file('./datasets/aloi/aloi.scale')\n",
    "        data = data.toarray()\n",
    "        n_tr = int(data.shape[0] * 0.9)\n",
    "        \n",
    "        self.train_data = data[:n_tr]\n",
    "        self.train_labels = labels[:n_tr]\n",
    "        \n",
    "        self.test_data = data[n_tr:]\n",
    "        self.test_labels = labels[n_tr:]\n",
    "    \n",
    "    def shuffle(self):\n",
    "        shuffle = np.random.permutation(self.train_data_size)\n",
    "        self.train_data = self.train_data[shuffle]\n",
    "        self.train_labels = self.train_labels[shuffle]\n",
    "        \n",
    "        shuffle = np.random.permutation(self.test_data_size)\n",
    "        self.test_data = self.test_data[shuffle]\n",
    "        self.test_labels = self.test_labels[shuffle]\n",
    "        \n",
    "    def generator(self, train=True):\n",
    "        if train:\n",
    "            for i in range(self.train_data_size):\n",
    "                yield (self.train_data[i].reshape(1, -1), self.train_labels[i])\n",
    "        else:\n",
    "            for i in range(self.test_data_size):\n",
    "                yield (self.test_data[i].reshape(1, -1), self.test_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class OnlineLogistRegression(object):\n",
    "    \n",
    "    def __init__(self, num_feature, eta0=0.01):\n",
    "        self.w = .01 * (np.random.rand(num_feature + 1) - 0.5)\n",
    "        self.lr = eta0\n",
    "    \n",
    "    def reset(self):\n",
    "        self.w = .01 * (np.random.rand(len(self.w)) - 0.5)\n",
    "        \n",
    "    def train(self, x, c):\n",
    "        A = np.concatenate((np.array([1]), x), axis=0)\n",
    "        y_hat = A.dot(self.w)\n",
    "        c_hat = 1 / (1 + np.exp(-y_hat))\n",
    "        \n",
    "        fgrad = A.T.dot(c_hat - c)\n",
    "        self.w = self.w - self.lr * fgrad\n",
    "        \n",
    "    def test(self, x):\n",
    "        A = np.concatenate((np.array([1]), x),axis=0)\n",
    "        y_hat = A.dot(self.w)\n",
    "        \n",
    "        return 1 / (1 + np.exp(-y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class OnlineClassification(object):\n",
    "    \n",
    "    def __init__(self, num_feature, learning_rate='constant', eta0=0.01):\n",
    "        self.classifier = SGDClassifier(learning_rate=learning_rate, eta0=eta0, warm_start=True)\n",
    "        \n",
    "    def train(self, x, c):\n",
    "        self.classifier.partial_fit(x, np.array([c]), [-1, 1])\n",
    "        \n",
    "    def test(self, x):\n",
    "        return self.classifier.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Node(object):\n",
    "    \n",
    "    def __init__(self, num_feature, learning_rate='constant', eta0=0.01):\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.parent = None\n",
    "        self.max_label = 1\n",
    "        self.max_label_count = 0\n",
    "        self.n_all = 0\n",
    "        self.m_all = 0\n",
    "        self.C = 0\n",
    "        self.l = {}\n",
    "        self.n = {}\n",
    "        self.m = {}\n",
    "        self.model = OnlineClassification(num_feature, learning_rate=learning_rate, eta0=eta0)\n",
    "#         self.model = OnlineLogistRegression(num_feature, eta0)\n",
    "    \n",
    "    def reset(self):\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.parent = None\n",
    "        self.max_label = 1\n",
    "        self.max_label_count = 0\n",
    "        self.n_all = 0\n",
    "        self.m_all = 0\n",
    "        self.C = 0\n",
    "        self.l.clear()\n",
    "        self.n.clear()\n",
    "        self.m.clear()\n",
    "\n",
    "    def testModel(self, x):\n",
    "        return self.model.test(x)\n",
    "    \n",
    "    def trainModel(self, x, c):\n",
    "        self.model.train(x, c)\n",
    "        \n",
    "    def addClass(self, class_name):\n",
    "        self.n[class_name] = 0\n",
    "        self.m[class_name] = 0\n",
    "        self.l[class_name] = 0\n",
    "        \n",
    "    def findExpectationAll(self):\n",
    "        if self.n_all == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return self.m_all / self.n_all\n",
    "        \n",
    "    def findExpectationOneClass(self, y):\n",
    "        if self.n[y] == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return self.m[y] / self.n[y]\n",
    "    \n",
    "    def judgeInTrain(self, y):\n",
    "        #c == -1: left, c == 1: right\n",
    "        return -1 if self.findExpectationAll() > self.findExpectationOneClass(y) else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Tree(object):\n",
    "    def __init__(self, T, data_loader, Rs=16, epoch=1, learning_rate='constant', eta0=0.01):\n",
    "        self.data_loader = data_loader\n",
    "        self.num_feature = data_loader.num_feature\n",
    "        self.eta0 = eta0;\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epoch = epoch\n",
    "        self.Rs = Rs\n",
    "        self.T = T\n",
    "        self.t = 1\n",
    "        self.size = 0\n",
    "        self.root = self.generateNode()\n",
    "        \n",
    "    def generateNode(self):\n",
    "        node = Node(self.num_feature, self.learning_rate, self.eta0)\n",
    "        self.size = self.size + 1\n",
    "        return node\n",
    "        \n",
    "    def split(self, node):\n",
    "        self.t = self.t + 1\n",
    "        left = self.generateNode()\n",
    "        right = self.generateNode()\n",
    "        \n",
    "        node.left = left\n",
    "        left.parent = node\n",
    "        node.right = right\n",
    "        right.parent = node\n",
    "        \n",
    "    def swap(self, node):\n",
    "        cur = self.root\n",
    "        while cur.left != None:\n",
    "            cur = cur.left if cur.left.C < cur.right.C else cur.right\n",
    "        \n",
    "        parent = cur.parent\n",
    "        grandpa = parent.parent\n",
    "        sib = parent.left if parent.left == cur else parent.right\n",
    "        if parent == grandpa.left:\n",
    "            grandpa.left = sib\n",
    "        else:\n",
    "            grandpa.right = sib\n",
    "        sib.parent = grandpa\n",
    "        \n",
    "        self.updateC(sib)\n",
    "        cur.reset()\n",
    "        parent.reset()\n",
    "        node.left = cur\n",
    "        cur.parent = node\n",
    "        node.right = parent\n",
    "        parent.parent = node\n",
    "        \n",
    "    def updateC(self, node):\n",
    "        while node != self.root and node.parent.C != node.C:\n",
    "            node = node.parent\n",
    "            node.C = min(node.left.C, node.right.C)\n",
    "    \n",
    "    def train(self):\n",
    "        start = time.time()\n",
    "        print('Start training.......')\n",
    "        for i in range(self.epoch):\n",
    "            train_generator = self.data_loader.generator(train=True)\n",
    "            for sample in train_generator:\n",
    "                self.onlineTrain(sample)\n",
    "            acc = self.test()\n",
    "            print('epoch %d: >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> accuracy=%f' % (i, acc))\n",
    "        end = time.time()\n",
    "        print('time used: %d s' % (end - start))\n",
    "    \n",
    "    def test(self):\n",
    "        test_generator = self.data_loader.generator(train=False)\n",
    "        test_result = []\n",
    "        for sample in test_generator:\n",
    "            x, y = sample\n",
    "            test_result.append(int(y == self.predict(x)))\n",
    "        acc = np.mean(test_result)\n",
    "        return acc\n",
    "        \n",
    "    def onlineTrain(self, xy):\n",
    "        x, y = xy\n",
    "        node = self.root\n",
    "        #register if y is new in this node\n",
    "        while node != None:\n",
    "            not_registered = node.l.get(y) == None\n",
    "            if not_registered:\n",
    "                node.addClass(y)\n",
    "            \n",
    "            node.l[y] += 1\n",
    "            \n",
    "            if node.l[y] > node.max_label_count:\n",
    "                node.max_label = y\n",
    "                node.max_label_count = node.l[y]\n",
    "\n",
    "            #give birth or swap in a leaf node if num_class >= 2 or \n",
    "            if node.left == None and len(node.n) > 1:\n",
    "                if self.t < self.T or node.C - node.l[node.max_label] > self.Rs * (self.root.C + 1):\n",
    "                    if self.t < self.T:\n",
    "                        #give birth\n",
    "                        self.split(node)\n",
    "                    else:\n",
    "                        #swap\n",
    "                        self.swap(node)\n",
    "                    node.left.C = node.C // 2\n",
    "                    node.right.C = node.C - node.left.C\n",
    "                    node.left.max_label = node.max_label\n",
    "                    node.right.max_label = node.max_label\n",
    "                    self.updateC(node.left)\n",
    "\n",
    "            #train if node is not leaf\n",
    "            if node.left != None:\n",
    "                c = node.judgeInTrain(y)\n",
    "                node.trainModel(x, c)\n",
    "                c_hat = node.testModel(x)\n",
    "                node.n_all += 1\n",
    "                node.m_all += c_hat\n",
    "                node.n[y] += 1\n",
    "                node.m[y] += c_hat\n",
    "                \n",
    "                node = node.left if c_hat == -1 else node.right\n",
    "            else:\n",
    "                node.C += 1\n",
    "                self.updateC(node)\n",
    "                break\n",
    "\n",
    "    def predict(self, x):\n",
    "        node = self.root\n",
    "        while node.left != None:\n",
    "            node = node.left if node.testModel(x) == -1 else node.right\n",
    "        return node.max_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data size: 6238, test data size: 1559\n"
     ]
    }
   ],
   "source": [
    "#build\n",
    "dataset_name = \"isolet\"\n",
    "data_loader = DataLoader(dataset_name)\n",
    "K = data_loader.num_class\n",
    "print('training data size: %d, test data size: %d' % (data_loader.train_data_size, data_loader.test_data_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_name='mnist', T=39, Rs=64, learning_rate='optimal', eta0=0.2, epoch=2\n",
      "Start training.......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Whisper\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-beed5817ad99>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'dataset_name=\\'%s\\', T=%d, Rs=%d, learning_rate=\\'%s\\', eta0=%.1f, epoch=%d'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0meta0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m#train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mLOM_tree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-804b7b2eee83>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     60\u001b[0m             \u001b[0mtrain_generator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0monlineTrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m             \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'epoch %d: >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> accuracy=%f'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-804b7b2eee83>\u001b[0m in \u001b[0;36monlineTrain\u001b[1;34m(self, xy)\u001b[0m\n\u001b[0;32m    108\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m                 \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjudgeInTrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m                 \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m                 \u001b[0mc_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtestModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m                 \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_all\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-faa3e2f4e12e>\u001b[0m in \u001b[0;36mtrainModel\u001b[1;34m(self, x, c)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtrainModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0maddClass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-1bfd9c044da3>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, x, c)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Whisper\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[1;34m(self, X, y, classes, sample_weight)\u001b[0m\n\u001b[0;32m    551\u001b[0m                                  \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m                                  \u001b[0mclasses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 553\u001b[1;33m                                  coef_init=None, intercept_init=None)\n\u001b[0m\u001b[0;32m    554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m     def fit(self, X, y, coef_init=None, intercept_init=None,\n",
      "\u001b[1;32mC:\\Users\\Whisper\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py\u001b[0m in \u001b[0;36m_partial_fit\u001b[1;34m(self, X, y, alpha, C, loss, learning_rate, max_iter, classes, sample_weight, coef_init, intercept_init)\u001b[0m\n\u001b[0;32m    403\u001b[0m                              \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m                              \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 405\u001b[1;33m                              max_iter=max_iter)\n\u001b[0m\u001b[0;32m    406\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m             raise ValueError(\"The number of class labels must be \"\n",
      "\u001b[1;32mC:\\Users\\Whisper\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py\u001b[0m in \u001b[0;36m_fit_binary\u001b[1;34m(self, X, y, alpha, C, sample_weight, learning_rate, max_iter)\u001b[0m\n\u001b[0;32m    459\u001b[0m                                               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_expanded_class_weight\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m                                               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_expanded_class_weight\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 461\u001b[1;33m                                               sample_weight)\n\u001b[0m\u001b[0;32m    462\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    463\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt_\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mn_iter_\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Whisper\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py\u001b[0m in \u001b[0;36mfit_binary\u001b[1;34m(est, i, X, y, alpha, C, learning_rate, max_iter, pos_weight, neg_weight, sample_weight)\u001b[0m\n\u001b[0;32m    297\u001b[0m                          \u001b[0mpos_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneg_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m                          \u001b[0mlearning_rate_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meta0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 299\u001b[1;33m                          est.power_t, est.t_, intercept_decay)\n\u001b[0m\u001b[0;32m    300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "T = 4 * K - 1\n",
    "Rs = 64\n",
    "learning_rate = 'optimal'\n",
    "eta0 = 0.25\n",
    "epoch = 2\n",
    "\n",
    "LOM_tree = Tree(T, data_loader, epoch=epoch, Rs=Rs, learning_rate=learning_rate, eta0=eta0)\n",
    "\n",
    "print('dataset_name=\\'%s\\', T=%d, Rs=%d, learning_rate=\\'%s\\', eta0=%.1f, epoch=%d' % (dataset_name, T, Rs, learning_rate,  eta0, epoch))\n",
    "#train\n",
    "LOM_tree.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3140 3094\n",
      "6\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "# check balance\n",
    "count = 0\n",
    "node = LOM_tree.root\n",
    "print(node.left.n_all, node.right.n_all)\n",
    "while node != None:\n",
    "    node = node.left\n",
    "    count += 1\n",
    "print(count)\n",
    "\n",
    "count = 0\n",
    "node = LOM_tree.root\n",
    "while node != None:\n",
    "    node = node.right\n",
    "    count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc=0.853111\n",
      "time=21.565372\n"
     ]
    }
   ],
   "source": [
    "# compare with traditional O(k) alogrithm\n",
    "start = time.time()\n",
    "model = SGDClassifier(max_iter=2, learning_rate=learning_rate, eta0=eta0, warm_start=True)\n",
    "gen = data_loader.generator()\n",
    "c = range(1, 27)\n",
    "for sample in gen:\n",
    "    x, y = sample\n",
    "    model.partial_fit(x, np.array([y]), c)\n",
    "acc = model.score(data_loader.test_data, data_loader.test_labels)\n",
    "end = time.time()\n",
    "print('acc=%f' % acc)\n",
    "print('time=%f' % (end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
