{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 157,
   "metadata": {},
=======
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
>>>>>>> 0ef2cf5b3e5e6d86275e41d81f84b48fadf17dc3
   "outputs": [],
   "source": [
    "class DataLoader(object):\n",
    "    \n",
    "    def __init__(self, dataset_name):\n",
    "        if dataset_name == \"mnist\":\n",
    "            self.loadMnistData()\n",
    "            self.num_class = 10\n",
    "        elif dataset_name == \"isolet\":\n",
    "            self.loadIsoletData()\n",
    "            self.num_class = 26\n",
    "        elif dataset_name == \"sector\":\n",
    "            self.loadSectorData()\n",
    "            self.num_class = 105\n",
    "        elif dataset_name == \"aloi\":\n",
    "            self.loadAloiData()\n",
    "            self.num_class = 1000\n",
    "        else:\n",
    "            raise ValueError('No such dataset name exists.')\n",
    "        \n",
    "        self.train_data_size = self.train_data.shape[0]\n",
    "        self.test_data_size = self.test_data.shape[0]\n",
    "        self.num_feature = self.train_data.shape[1]\n",
    "        \n",
    "        self.shuffle()\n",
    "    \n",
    "    def loadMnistData(self):\n",
    "        train_data, train_labels = load_svmlight_file('./datasets/mnist/mnist.scale')\n",
    "        self.train_data = train_data.toarray()\n",
    "        self.train_labels = train_labels\n",
    "        test_data, test_labels = load_svmlight_file('./datasets/mnist/mnist.scale.t')\n",
    "        self.test_data = test_data.toarray()\n",
    "        self.test_labels = test_labels\n",
    "            \n",
    "    def loadIsoletData(self):\n",
    "        train_set = np.genfromtxt('./datasets/isolet/isolet_data.data',\n",
    "                         dtype=None,\n",
    "                         delimiter=',')\n",
    "        test_set = np.genfromtxt('./datasets/isolet/isolet5.data',\n",
    "                         dtype=None,\n",
    "                         delimiter=',')\n",
    "        \n",
    "        self.train_data = train_set[:,:-1]\n",
    "        self.train_labels = train_set[:,-1].astype(int)\n",
    "        self.test_data = test_set[:,:-1]\n",
    "        self.test_labels = test_set[:,-1].astype(int) \n",
    "    \n",
    "    def loadSectorData(self):\n",
    "        data, labels = load_svmlight_file('./datasets/sector/sector.scale')\n",
    "        data = data.toarray()\n",
    "        n_tr = int(data.shape[0] * 0.9)\n",
    "        \n",
    "        self.train_data = data[:n_tr]\n",
    "        self.train_labels = labels[:n_tr]\n",
    "        \n",
    "        self.test_data = data[n_tr:]\n",
    "        self.test_labels = labels[n_tr:]\n",
    "        \n",
    "    def loadAloiData(self):\n",
    "        data, labels = load_svmlight_file('./datasets/aloi/aloi.scale')\n",
    "        data = data.toarray()\n",
    "        n_tr = int(data.shape[0] * 0.9)\n",
    "        \n",
    "        self.train_data = data[:n_tr]\n",
    "        self.train_labels = labels[:n_tr]\n",
    "        \n",
    "        self.test_data = data[n_tr:]\n",
    "        self.test_labels = labels[n_tr:]\n",
    "    \n",
    "    def shuffle(self):\n",
    "        shuffle = np.random.permutation(self.train_data_size)\n",
    "        self.train_data = self.train_data[shuffle]\n",
    "        self.train_labels = self.train_labels[shuffle]\n",
    "        \n",
    "        shuffle = np.random.permutation(self.test_data_size)\n",
    "        self.test_data = self.test_data[shuffle]\n",
    "        self.test_labels = self.test_labels[shuffle]\n",
    "        \n",
    "    def generator(self, train=True):\n",
    "        if train:\n",
    "            for i in range(self.train_data_size):\n",
    "                yield (self.train_data[i].reshape(1, -1), self.train_labels[i])\n",
    "        else:\n",
    "            for i in range(self.test_data_size):\n",
    "                yield (self.test_data[i].reshape(1, -1), self.test_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class OnlineLogistRegression(object):\n",
    "    \n",
    "    def __init__(self, num_feature, eta0=0.01):\n",
    "        self.w = .01 * (np.random.rand(num_feature + 1) - 0.5)\n",
    "        self.lr = eta0\n",
    "    \n",
    "    def reset(self):\n",
    "        self.w = .01 * (np.random.rand(len(self.w)) - 0.5)\n",
    "        \n",
    "    def train(self, x, c):\n",
    "        A = np.concatenate((np.array([1]), x), axis=0)\n",
    "        y_hat = A.dot(self.w)\n",
    "        c_hat = 1 / (1 + np.exp(-y_hat))\n",
    "        \n",
    "        fgrad = A.T.dot(c_hat - c)\n",
    "        self.w = self.w - self.lr * fgrad\n",
    "        \n",
    "    def test(self, x):\n",
    "        A = np.concatenate((np.array([1]), x),axis=0)\n",
    "        y_hat = A.dot(self.w)\n",
    "        \n",
    "        return 1 / (1 + np.exp(-y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class OnlineClassification(object):\n",
    "    \n",
    "    def __init__(self, num_feature, learning_rate='constant', eta0=0.01):\n",
    "        self.classifier = SGDClassifier(learning_rate=learning_rate, eta0=eta0, warm_start=True)\n",
    "        \n",
    "    def train(self, x, c):\n",
    "        self.classifier.partial_fit(x, np.array([c]), [-1, 1])\n",
    "        \n",
    "    def test(self, x):\n",
    "        return self.classifier.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Node(object):\n",
    "    \n",
    "    def __init__(self, num_feature, learning_rate='constant', eta0=0.01):\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.parent = None\n",
    "        self.max_label = 1\n",
    "        self.max_label_count = 0\n",
    "        self.n_all = 0\n",
    "        self.m_all = 0\n",
    "        self.C = 0\n",
    "        self.l = {}\n",
    "        self.n = {}\n",
    "        self.m = {}\n",
    "        self.model = OnlineClassification(num_feature, learning_rate=learning_rate, eta0=eta0)\n",
    "#         self.model = OnlineLogistRegression(num_feature, eta0)\n",
    "    \n",
    "    def reset(self):\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.parent = None\n",
    "        self.max_label = 1\n",
    "        self.max_label_count = 0\n",
    "        self.n_all = 0\n",
    "        self.m_all = 0\n",
    "        self.C = 0\n",
    "        self.l.clear()\n",
    "        self.n.clear()\n",
    "        self.m.clear()\n",
    "\n",
    "    def testModel(self, x):\n",
    "        return self.model.test(x)\n",
    "    \n",
    "    def trainModel(self, x, c):\n",
    "        self.model.train(x, c)\n",
    "        \n",
    "    def addClass(self, class_name):\n",
    "        self.n[class_name] = 0\n",
    "        self.m[class_name] = 0\n",
    "        self.l[class_name] = 0\n",
    "        \n",
    "    def findExpectationAll(self):\n",
    "        if self.n_all == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return self.m_all / self.n_all\n",
    "        \n",
    "    def findExpectationOneClass(self, y):\n",
    "        if self.n[y] == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return self.m[y] / self.n[y]\n",
    "    \n",
    "    def judgeInTrain(self, y):\n",
    "        #c == -1: left, c == 1: right\n",
    "        return -1 if self.findExpectationAll() > self.findExpectationOneClass(y) else 1"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
=======
   "execution_count": 6,
   "metadata": {},
>>>>>>> 0ef2cf5b3e5e6d86275e41d81f84b48fadf17dc3
   "outputs": [],
   "source": [
    "class Tree(object):\n",
    "    def __init__(self, T, data_loader, Rs=16, epoch=1, learning_rate='constant', eta0=0.01):\n",
    "        self.data_loader = data_loader\n",
    "        self.num_feature = data_loader.num_feature\n",
    "        self.eta0 = eta0;\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epoch = epoch\n",
    "        self.Rs = Rs\n",
    "        self.T = T\n",
    "        self.t = 1\n",
    "        self.size = 0\n",
    "        self.root = self.generateNode()\n",
    "        \n",
    "    def generateNode(self):\n",
    "        node = Node(self.num_feature, self.learning_rate, self.eta0)\n",
    "        self.size = self.size + 1\n",
    "        return node\n",
    "        \n",
    "    def split(self, node):\n",
    "        self.t = self.t + 1\n",
    "        left = self.generateNode()\n",
    "        right = self.generateNode()\n",
    "        \n",
    "        node.left = left\n",
    "        left.parent = node\n",
    "        node.right = right\n",
    "        right.parent = node\n",
    "        \n",
    "    def swap(self, node):\n",
    "        cur = self.root\n",
    "        while cur.left != None:\n",
    "            cur = cur.left if cur.left.C < cur.right.C else cur.right\n",
    "        \n",
    "        parent = cur.parent\n",
    "        grandpa = parent.parent\n",
    "        sib = parent.left if parent.left == cur else parent.right\n",
    "        if parent == grandpa.left:\n",
    "            grandpa.left = sib\n",
    "        else:\n",
    "            grandpa.right = sib\n",
    "        sib.parent = grandpa\n",
    "        \n",
    "        self.updateC(sib)\n",
    "        cur.reset()\n",
    "        parent.reset()\n",
    "        node.left = cur\n",
    "        cur.parent = node\n",
    "        node.right = parent\n",
    "        parent.parent = node\n",
    "        \n",
    "    def updateC(self, node):\n",
    "        while node != self.root and node.parent.C != node.C:\n",
    "            node = node.parent\n",
    "            node.C = min(node.left.C, node.right.C)\n",
    "    \n",
    "    def train(self):\n",
    "        start = time.time()\n",
    "        print('Start training.......')\n",
    "        for i in range(self.epoch):\n",
    "            train_generator = self.data_loader.generator(train=True)\n",
    "            for sample in train_generator:\n",
    "                self.onlineTrain(sample)\n",
    "            acc = self.test()\n",
    "            print('epoch %d: >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> accuracy=%f' % (i, acc))\n",
    "        end = time.time()\n",
    "        print('time used: %d s' % (end - start))\n",
    "    \n",
    "    def test(self):\n",
    "        test_generator = self.data_loader.generator(train=False)\n",
    "        test_result = []\n",
    "        for sample in test_generator:\n",
    "            x, y = sample\n",
    "            test_result.append(int(y == self.predict(x)))\n",
    "        acc = np.mean(test_result)\n",
    "        return acc\n",
    "        \n",
    "    def onlineTrain(self, xy):\n",
    "        x, y = xy\n",
    "        node = self.root\n",
    "        #register if y is new in this node\n",
    "        while node != None:\n",
    "            not_registered = node.l.get(y) == None\n",
    "            if not_registered:\n",
    "                node.addClass(y)\n",
    "            \n",
    "            node.l[y] += 1\n",
    "            \n",
    "            if node.l[y] > node.max_label_count:\n",
    "                node.max_label = y\n",
    "                node.max_label_count = node.l[y]\n",
    "\n",
    "            #give birth or swap in a leaf node if num_class >= 2 or \n",
    "            if node.left == None and len(node.n) > 1:\n",
    "                if self.t < self.T or node.C - node.l[node.max_label] > self.Rs * (self.root.C + 1):\n",
    "                    if self.t < self.T:\n",
    "                        #give birth\n",
    "                        self.split(node)\n",
    "                    else:\n",
    "                        #swap\n",
    "                        self.swap(node)\n",
    "                    node.left.C = node.C // 2\n",
    "                    node.right.C = node.C - node.left.C\n",
    "                    node.left.max_label = node.max_label\n",
    "                    node.right.max_label = node.max_label\n",
    "                    self.updateC(node.left)\n",
    "\n",
    "            #train if node is not leaf\n",
    "            if node.left != None:\n",
    "                c = node.judgeInTrain(y)\n",
    "                node.trainModel(x, c)\n",
    "                c_hat = node.testModel(x)\n",
    "                node.n_all += 1\n",
    "                node.m_all += c_hat\n",
    "                node.n[y] += 1\n",
    "                node.m[y] += c_hat\n",
    "                \n",
    "                node = node.left if c_hat == -1 else node.right\n",
    "            else:\n",
    "                node.C += 1\n",
    "                self.updateC(node)\n",
    "                break\n",
    "\n",
    "    def predict(self, x):\n",
    "        node = self.root\n",
    "        while node.left != None:\n",
    "            node = node.left if node.testModel(x) == -1 else node.right\n",
    "        return node.max_label"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 161,
=======
   "execution_count": 7,
>>>>>>> 0ef2cf5b3e5e6d86275e41d81f84b48fadf17dc3
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data size: 6238, test data size: 1559\n"
     ]
    }
   ],
   "source": [
    "#build\n",
    "dataset_name = \"isolet\"\n",
    "data_loader = DataLoader(dataset_name)\n",
    "K = data_loader.num_class\n",
    "print('training data size: %d, test data size: %d' % (data_loader.train_data_size, data_loader.test_data_size))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 168,
=======
   "execution_count": 8,
>>>>>>> 0ef2cf5b3e5e6d86275e41d81f84b48fadf17dc3
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "accurancy = 0.353\n"
=======
      "dataset_name='isolet', T=103, Rs=64, learning_rate='optimal', eta0=0.2, epoch=1\n",
      "Start training.......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Whisper\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> accuracy=0.729314\n",
      "time used: 16 s\n"
>>>>>>> 0ef2cf5b3e5e6d86275e41d81f84b48fadf17dc3
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "my_tree = Tree(data_loader, lr=30)\n",
    "my_generator = data_loader.generator()\n",
    "#train\n",
    "for i in range(5412):\n",
    "    my_tree.startOnlineTrain(next(my_generator))\n",
    "    \n",
    "#test\n",
    "test_result = []\n",
    "for i in range(1000):\n",
    "    x, y = next(my_generator)\n",
    "    test_result.append(int(y == my_tree.startOnlineTest(x)))\n",
    "accurancy = np.mean(test_result)\n",
    "print('accurancy =', accurancy)"
=======
    "T = 4 * K - 1\n",
    "Rs = 64\n",
    "learning_rate = 'optimal'\n",
    "eta0 = 0.25\n",
    "epoch = 1\n",
    "\n",
    "LOM_tree = Tree(T, data_loader, epoch=epoch, Rs=Rs, learning_rate=learning_rate, eta0=eta0)\n",
    "\n",
    "print('dataset_name=\\'%s\\', T=%d, Rs=%d, learning_rate=\\'%s\\', eta0=%.1f, epoch=%d' % (dataset_name, T, Rs, learning_rate,  eta0, epoch))\n",
    "#train\n",
    "LOM_tree.train()"
>>>>>>> 0ef2cf5b3e5e6d86275e41d81f84b48fadf17dc3
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
=======
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3140 3094\n",
      "6\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "# check balance\n",
    "count = 0\n",
    "node = LOM_tree.root\n",
    "print(node.left.n_all, node.right.n_all)\n",
    "while node != None:\n",
    "    node = node.left\n",
    "    count += 1\n",
    "print(count)\n",
    "\n",
    "count = 0\n",
    "node = LOM_tree.root\n",
    "while node != None:\n",
    "    node = node.right\n",
    "    count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc=0.853111\n",
      "time=21.565372\n"
     ]
    }
   ],
>>>>>>> 0ef2cf5b3e5e6d86275e41d81f84b48fadf17dc3
   "source": [
    "# compare with traditional O(k) alogrithm\n",
    "start = time.time()\n",
    "model = SGDClassifier(max_iter=2, learning_rate=learning_rate, eta0=eta0, warm_start=True)\n",
    "gen = data_loader.generator()\n",
    "c = range(1, 27)\n",
    "for sample in gen:\n",
    "    x, y = sample\n",
    "    model.partial_fit(x, np.array([y]), c)\n",
    "acc = model.score(data_loader.test_data, data_loader.test_labels)\n",
    "end = time.time()\n",
    "print('acc=%f' % acc)\n",
    "print('time=%f' % (end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
