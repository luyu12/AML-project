{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DataLoader(object):\n",
    "    \n",
    "    def __init__(self, dataset_name):\n",
    "        if dataset_name == \"mnist\":\n",
    "            self.loadMnistData()\n",
    "            self.num_class = 10\n",
    "        elif dataset_name == \"isolet\":\n",
    "            self.loadIsoletData()\n",
    "            self.num_class = 26\n",
    "        elif dataset_name == \"sector\":\n",
    "            self.loadSectorData()\n",
    "            self.num_class = 105\n",
    "        elif dataset_name == \"aloi\":\n",
    "            self.loadAloiData()\n",
    "            self.num_class = 1000\n",
    "        else:\n",
    "            raise ValueError('No such dataset name exists.')\n",
    "        \n",
    "        self.train_data_size = self.train_data.shape[0]\n",
    "        self.test_data_size = self.test_data.shape[0]\n",
    "        self.num_feature = self.train_data.shape[1]\n",
    "        \n",
    "        self.shuffle()\n",
    "    \n",
    "    def loadMnistData(self):\n",
    "        train_data, train_labels = load_svmlight_file('./datasets/multiclass/mnist/mnist.scale')\n",
    "        self.train_data = train_data.toarray()\n",
    "        self.train_labels = train_labels\n",
    "        test_data, test_labels = load_svmlight_file('./datasets/multiclass/mnist/mnist.scale.t')\n",
    "        self.test_data = test_data.toarray()\n",
    "        self.test_labels = test_labels\n",
    "            \n",
    "    def loadIsoletData(self):\n",
    "        train_set = np.genfromtxt('./datasets/multiclass/isolet/isolet_data.data',\n",
    "                         dtype=None,\n",
    "                         delimiter=',')\n",
    "        test_set = np.genfromtxt('./datasets/multiclass/isolet/isolet5.data',\n",
    "                         dtype=None,\n",
    "                         delimiter=',')\n",
    "        \n",
    "        self.train_data = train_set[:,:-1]\n",
    "        self.train_labels = train_set[:,-1].astype(int)\n",
    "        self.test_data = test_set[:,:-1]\n",
    "        self.test_labels = test_set[:,-1].astype(int) \n",
    "    \n",
    "    def loadSectorData(self):\n",
    "        data, labels = load_svmlight_file('./datasets/multiclass/sector/sector.scale')\n",
    "        data = data.toarray()\n",
    "        n_tr = int(data.shape[0] * 0.9)\n",
    "        \n",
    "        self.train_data = data[:n_tr]\n",
    "        self.train_labels = labels[:n_tr]\n",
    "        \n",
    "        self.test_data = data[n_tr:]\n",
    "        self.test_labels = labels[n_tr:]\n",
    "        \n",
    "    def loadAloiData(self):\n",
    "        data, labels = load_svmlight_file('./datasets/multiclass/aloi/aloi.scale')\n",
    "        data = data.toarray()\n",
    "        n_tr = int(data.shape[0] * 0.9)\n",
    "        shuffle = np.random.permutation(data.shape[0])\n",
    "        data = data[shuffle]\n",
    "        labels = labels[shuffle]\n",
    "        \n",
    "        self.train_data = data[:n_tr]\n",
    "        self.train_labels = labels[:n_tr]\n",
    "        \n",
    "        self.test_data = data[n_tr:]\n",
    "        self.test_labels = labels[n_tr:]\n",
    "    \n",
    "    def shuffle(self):\n",
    "        shuffle = np.random.permutation(self.train_data_size)\n",
    "        self.train_data = self.train_data[shuffle]\n",
    "        self.train_labels = self.train_labels[shuffle]\n",
    "        \n",
    "        shuffle = np.random.permutation(self.test_data_size)\n",
    "        self.test_data = self.test_data[shuffle]\n",
    "        self.test_labels = self.test_labels[shuffle]\n",
    "        \n",
    "    def generator(self, train=True):\n",
    "        if train:\n",
    "            for i in range(self.train_data_size):\n",
    "                yield (self.train_data[i].reshape(1, -1), self.train_labels[i])\n",
    "        else:\n",
    "            for i in range(self.test_data_size):\n",
    "                yield (self.test_data[i].reshape(1, -1), self.test_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class OnlineLogistRegression(object):\n",
    "    \n",
    "    def __init__(self, num_feature, eta0=0.01):\n",
    "        self.w = .01 * (np.random.rand(num_feature + 1) - 0.5)\n",
    "        self.lr = eta0\n",
    "    \n",
    "    def reset(self):\n",
    "        self.w = .01 * (np.random.rand(len(self.w)) - 0.5)\n",
    "        \n",
    "    def train(self, x, c):\n",
    "        A = np.concatenate((np.array([1]), x), axis=0)\n",
    "        y_hat = A.dot(self.w)\n",
    "        c_hat = 1 / (1 + np.exp(-y_hat))\n",
    "        \n",
    "        fgrad = A.T.dot(c_hat - c)\n",
    "        self.w = self.w - self.lr * fgrad\n",
    "        \n",
    "    def test(self, x):\n",
    "        A = np.concatenate((np.array([1]), x),axis=0)\n",
    "        y_hat = A.dot(self.w)\n",
    "        \n",
    "        return 1 / (1 + np.exp(-y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class OnlineClassification(object):\n",
    "    \n",
    "    def __init__(self, num_feature, learning_rate='constant', eta0=0.01):\n",
    "        self.classifier = SGDClassifier(max_iter=5, learning_rate=learning_rate, eta0=eta0, warm_start=True)\n",
    "        \n",
    "    def train(self, x, c):\n",
    "        self.classifier.partial_fit(x, np.array([c]), [-1, 1])\n",
    "        \n",
    "    def test(self, x):\n",
    "        return self.classifier.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Node(object):\n",
    "    \n",
    "    def __init__(self, num_feature, learning_rate='constant', eta0=0.01):\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.parent = None\n",
    "        self.max_label = 1\n",
    "        self.max_label_count = 0\n",
    "        self.n_all = 0\n",
    "        self.m_all = 0\n",
    "        self.C = 0\n",
    "        self.l = {}\n",
    "        self.n = {}\n",
    "        self.m = {}\n",
    "        self.model = OnlineClassification(num_feature, learning_rate=learning_rate, eta0=eta0)\n",
    "    \n",
    "    def reset(self):\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.parent = None\n",
    "        self.max_label = 1\n",
    "        self.max_label_count = 0\n",
    "        self.n_all = 0\n",
    "        self.m_all = 0\n",
    "        self.C = 0\n",
    "        self.l.clear()\n",
    "        self.n.clear()\n",
    "        self.m.clear()\n",
    "\n",
    "    def testModel(self, x):\n",
    "        return self.model.test(x)\n",
    "    \n",
    "    def trainModel(self, x, c):\n",
    "        self.model.train(x, c)\n",
    "        \n",
    "    def addClass(self, class_name):\n",
    "        self.n[class_name] = 0\n",
    "        self.m[class_name] = 0\n",
    "        self.l[class_name] = 0\n",
    "        \n",
    "    def findExpectationAll(self):\n",
    "        if self.n_all == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return self.m_all / self.n_all\n",
    "        \n",
    "    def findExpectationOneClass(self, y):\n",
    "        if self.n[y] == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return self.m[y] / self.n[y]\n",
    "    \n",
    "    def judgeInTrain(self, y):\n",
    "        #c == -1: left, c == 1: right\n",
    "        return -1 if self.findExpectationAll() > self.findExpectationOneClass(y) else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Tree(object):\n",
    "    def __init__(self, T, data_loader, Rs=16, epoch=1, learning_rate='constant', eta0=0.01):\n",
    "        self.data_loader = data_loader\n",
    "        self.num_feature = data_loader.num_feature\n",
    "        self.eta0 = eta0;\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epoch = epoch\n",
    "        self.Rs = Rs\n",
    "        self.T = T\n",
    "        self.t = 1\n",
    "        self.size = 0\n",
    "        self.root = self.generateNode()\n",
    "        \n",
    "    def generateNode(self):\n",
    "        node = Node(self.num_feature, self.learning_rate, self.eta0)\n",
    "        self.size = self.size + 1\n",
    "        return node\n",
    "        \n",
    "    def split(self, node):\n",
    "        self.t = self.t + 1\n",
    "        left = self.generateNode()\n",
    "        right = self.generateNode()\n",
    "        \n",
    "        node.left = left\n",
    "        left.parent = node\n",
    "        node.right = right\n",
    "        right.parent = node\n",
    "        \n",
    "    def swap(self, node):\n",
    "        cur = self.root\n",
    "        while cur.left != None:\n",
    "            cur = cur.left if cur.left.C < cur.right.C else cur.right\n",
    "        \n",
    "        parent = cur.parent\n",
    "        grandpa = parent.parent\n",
    "        sib = parent.left if parent.left == cur else parent.right\n",
    "        if parent == grandpa.left:\n",
    "            grandpa.left = sib\n",
    "        else:\n",
    "            grandpa.right = sib\n",
    "        sib.parent = grandpa\n",
    "        \n",
    "        self.updateC(sib)\n",
    "        cur.reset()\n",
    "        parent.reset()\n",
    "        node.left = cur\n",
    "        cur.parent = node\n",
    "        node.right = parent\n",
    "        parent.parent = node\n",
    "        \n",
    "    def updateC(self, node):\n",
    "        while node != self.root and node.parent.C != node.C:\n",
    "            node = node.parent\n",
    "            node.C = min(node.left.C, node.right.C)\n",
    "    \n",
    "    def train(self):\n",
    "        start = time.time()\n",
    "        print('Start training.......')\n",
    "        for i in range(self.epoch):\n",
    "            train_generator = self.data_loader.generator(train=True)\n",
    "            for sample in train_generator:\n",
    "                self.onlineTrain(sample)\n",
    "            acc = self.test()\n",
    "            print('epoch %d: >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> accuracy=%f' % (i, acc))\n",
    "        end = time.time()\n",
    "        print('time used: %.3f s' % (end - start))\n",
    "    \n",
    "    def test(self):\n",
    "        test_generator = self.data_loader.generator(train=False)\n",
    "        test_result = []\n",
    "        for sample in test_generator:\n",
    "            x, y = sample\n",
    "            y_hat = self.predict(x)\n",
    "            test_result.append(int(y == y_hat))\n",
    "        acc = np.mean(test_result)\n",
    "        return acc\n",
    "        \n",
    "    def onlineTrain(self, xy):\n",
    "        x, y = xy\n",
    "        node = self.root\n",
    "        #register if y is new in this node\n",
    "        while node != None:\n",
    "            not_registered = node.l.get(y) == None\n",
    "            if not_registered:\n",
    "                node.addClass(y)\n",
    "            \n",
    "            node.l[y] += 1\n",
    "            \n",
    "            if node.l[y] > node.max_label_count:\n",
    "                node.max_label = y\n",
    "                node.max_label_count = node.l[y]\n",
    "\n",
    "            #give birth or swap in a leaf node if num_class >= 2 or \n",
    "            if node.left == None and len(node.n) > 1:\n",
    "                if self.t < self.T or node.C - node.l[node.max_label] > self.Rs * (self.root.C + 1):\n",
    "                    if self.t < self.T:\n",
    "                        #give birth\n",
    "                        self.split(node)\n",
    "                    else:\n",
    "                        #swap\n",
    "                        self.swap(node)\n",
    "                    node.left.C = node.C // 2\n",
    "                    node.right.C = node.C - node.left.C\n",
    "                    node.left.max_label = node.max_label\n",
    "                    node.right.max_label = node.max_label\n",
    "                    self.updateC(node.left)\n",
    "\n",
    "            #train if node is not leaf\n",
    "            if node.left != None:\n",
    "                c = node.judgeInTrain(y)\n",
    "                node.trainModel(x, c)\n",
    "                c_hat = node.testModel(x)\n",
    "                node.n_all += 1\n",
    "                node.m_all += c_hat\n",
    "                node.n[y] += 1\n",
    "                node.m[y] += c_hat\n",
    "                \n",
    "                node = node.left if c_hat == -1 else node.right\n",
    "            else:\n",
    "                node.C += 1\n",
    "                self.updateC(node)\n",
    "                break\n",
    "\n",
    "    def predict(self, x):\n",
    "        node = self.root\n",
    "        while node.left != None:\n",
    "            node = node.left if node.testModel(x) == -1 else node.right\n",
    "        return node.max_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data size: 97200, test data size: 10800, num of features: 128, num of classes: 1000\n"
     ]
    }
   ],
   "source": [
    "#build\n",
    "dataset_name = \"aloi\"\n",
    "data_loader = DataLoader(dataset_name)\n",
    "K = data_loader.num_class\n",
    "print('training data size: %d, test data size: %d, num of features: %d, num of classes: %d' \n",
    "      % (data_loader.train_data_size, data_loader.test_data_size, data_loader.num_feature, data_loader.num_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_name='aloi', T=3999, Rs=2048, learning_rate='optimal', eta0=0.5, epoch=1\n"
     ]
    }
   ],
   "source": [
    "T = 4 * K - 1\n",
    "Rs = 2048\n",
    "learning_rate = 'optimal'\n",
    "eta0 = 0.5\n",
    "epoch = 1\n",
    "\n",
    "LOM_tree = Tree(T, data_loader, epoch=epoch, Rs=Rs, learning_rate=learning_rate, eta0=eta0)\n",
    "\n",
    "print('dataset_name=\\'%s\\', T=%d, Rs=%d, learning_rate=\\'%s\\', eta0=%.1f, epoch=%d' \n",
    "      % (dataset_name, T, Rs, learning_rate,  eta0, epoch))\n",
    "#train\n",
    "LOM_tree.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2871 3364\n",
      "6\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "# check balance\n",
    "count = 0\n",
    "node = LOM_tree.root\n",
    "print(node.left.n_all, node.right.n_all)\n",
    "while node != None:\n",
    "    node = node.left\n",
    "    count += 1\n",
    "print(count)\n",
    "\n",
    "count = 0\n",
    "node = LOM_tree.root\n",
    "while node != None:\n",
    "    node = node.right\n",
    "    count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "classes should include all valid labels that can be in y",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-1945776e8b89>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgen\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Whisper\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[1;34m(self, X, y, classes, sample_weight)\u001b[0m\n\u001b[0;32m    551\u001b[0m                                  \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m                                  \u001b[0mclasses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 553\u001b[1;33m                                  coef_init=None, intercept_init=None)\n\u001b[0m\u001b[0;32m    554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m     def fit(self, X, y, coef_init=None, intercept_init=None,\n",
      "\u001b[1;32mC:\\Users\\Whisper\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py\u001b[0m in \u001b[0;36m_partial_fit\u001b[1;34m(self, X, y, alpha, C, loss, learning_rate, max_iter, classes, sample_weight, coef_init, intercept_init)\u001b[0m\n\u001b[0;32m    379\u001b[0m         \u001b[1;31m# Allocate datastructures from input arguments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    380\u001b[0m         self._expanded_class_weight = compute_class_weight(self.class_weight,\n\u001b[1;32m--> 381\u001b[1;33m                                                            self.classes_, y)\n\u001b[0m\u001b[0;32m    382\u001b[0m         \u001b[0msample_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_sample_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Whisper\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\class_weight.py\u001b[0m in \u001b[0;36mcompute_class_weight\u001b[1;34m(class_weight, classes, y)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m         raise ValueError(\"classes should include all valid labels that can \"\n\u001b[0m\u001b[0;32m     43\u001b[0m                          \"be in y\")\n\u001b[0;32m     44\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mclass_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: classes should include all valid labels that can be in y"
     ]
    }
   ],
   "source": [
    "# compare with OAA\n",
    "start = time.time()\n",
    "model = SGDClassifier(max_iter=2, learning_rate=learning_rate, eta0=eta0, warm_start=True)\n",
    "gen = data_loader.generator()\n",
    "c = range(1, data_loader.num_class + 1)\n",
    "for sample in gen:\n",
    "    x, y = sample\n",
    "    model.partial_fit(x, np.array([y]), c)\n",
    "acc = model.score(data_loader.test_data, data_loader.test_labels)\n",
    "end = time.time()\n",
    "print('acc=%f' % acc)\n",
    "print('time=%.3f' % (end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
